{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import chi2, ncx2\n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "corr_shape = (10, 20)\n",
    "mock_corr = np.random.randn(corr_shape[0], corr_shape[1]) + 1j * np.random.randn(corr_shape[0], corr_shape[1])\n",
    "# mock_corr[4, 12] += 10  # Add a peak\n",
    "im = ax.imshow(np.abs(mock_corr), extent=(0, corr_shape[1], corr_shape[0], 0), vmin=0, vmax=10)\n",
    "ax.set_xticks(np.arange(0, corr_shape[1]+1, 2))\n",
    "ax.set_xlabel(\"Code Phase Offset [chips]\")\n",
    "ax.set_ylabel(\"Doppler Shift [Hz]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make joint normal random pdf in 3D\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D # For 3D surface plot\n",
    "\n",
    "# 1. Define the parameters of the 2D joint normal distribution\n",
    "mean = np.array([0, 0])  # Mean vector (mu_x, mu_y)\n",
    "covariance = np.array([[1, 0.5],\n",
    "                       [0.5, 1]]) # Covariance matrix\n",
    "\n",
    "# 2. Create a grid of points for the X and Y axes\n",
    "N = 1000 # Number of points in each dimension\n",
    "x = np.linspace(-3, 3, N)\n",
    "y = np.linspace(-3, 3, N)\n",
    "X, Y = np.meshgrid(x, y) # Create a 2D grid\n",
    "\n",
    "# 3. Combine X and Y into a single array of coordinates\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y\n",
    "\n",
    "# 4. Create a multivariate normal distribution object\n",
    "rv = multivariate_normal(mean, covariance)\n",
    "\n",
    "# 5. Calculate the PDF values for each point on the grid\n",
    "Z = rv.pdf(pos)\n",
    "\n",
    "# 6. Plot the 2D joint normal PDF\n",
    "fig = plt.figure(figsize=(10, 7), dpi=200)\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Create a 3D surface plot\n",
    "ax.plot_surface(X, Y, Z, cmap=\"plasma\", antialiased=False, edgecolor=\"none\", alpha=1.0)\n",
    "# ax.set_xlabel(\"$X_1$\")\n",
    "# ax.set_ylabel(\"$X_2$\")\n",
    "# ax.set_zlabel(\"pdf($X_1, X_2$)\")\n",
    "ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "ax.yaxis.gridlines.set_visible(False)\n",
    "ax.xaxis.gridlines.set_visible(False)\n",
    "ax.zaxis.gridlines.set_visible(False)\n",
    "# ax.zaxis.set_ticks([])\n",
    "# ax.set_zticks([])\n",
    "for axis in [ax.xaxis, ax.yaxis, ax.zaxis]:\n",
    "    axis.set_ticklabels([])\n",
    "#     axis._axinfo[\"axisline\"][\"linewidth\"] = 1\n",
    "#     axis._axinfo[\"axisline\"][\"color\"] = \"b\"\n",
    "#     axis._axinfo[\"grid\"][\"linewidth\"] = 0.5\n",
    "#     axis._axinfo[\"grid\"][\"linestyle\"] = \"--\"\n",
    "#     axis._axinfo[\"grid\"][\"color\"] = \"#d1d1d1\"\n",
    "#     axis._axinfo[\"tick\"][\"inward_factor\"] = 0.0\n",
    "#     axis._axinfo[\"tick\"][\"outward_factor\"] = 0.0\n",
    "    # axis.set_pane_color((0, 0, 0))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0, 0])  # Mean vector (mu_x, mu_y)\n",
    "covariance = np.array([[2, 0.0],\n",
    "                       [0.0, 1]])\n",
    "# covariance = np.array([[2, 0.7],\n",
    "#                        [0.7, 1]])\n",
    "\n",
    "# 2. Create a grid of points for the X and Y axes\n",
    "N = 1000 # Number of points in each dimension\n",
    "x = np.linspace(-4, 4, N)\n",
    "y = np.linspace(-4, 4, N)\n",
    "X, Y = np.meshgrid(x, y) # Create a 2D grid\n",
    "\n",
    "# 3. Combine X and Y into a single array of coordinates\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y\n",
    "\n",
    "# 4. Create a multivariate normal distribution object\n",
    "rv = multivariate_normal(mean, covariance)\n",
    "\n",
    "# 5. Calculate the PDF values for each point on the grid\n",
    "Z = rv.pdf(pos)\n",
    "\n",
    "# Plot contour of the 2D joint normal PDF\n",
    "fig = plt.figure(figsize=(8, 6), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "contour = ax.contourf(X, Y, Z, levels=20, cmap=\"Purples\", vmin=-0, vmax=.12, zorder=2, alpha=.9)\n",
    "ax.set_xlabel(\"$X_1$\")\n",
    "ax.set_ylabel(\"$X_2$\")\n",
    "ax.set_yticks([-4, -2, 0, 2, 4])\n",
    "ax.set_xticks([-2, 0, 2, 4])\n",
    "for sp in ax.spines.values():\n",
    "    sp.set_visible(False)\n",
    "ax.grid(zorder=1)\n",
    "cb = plt.colorbar(contour, ax=ax, label=\"pdf\", shrink=0.6)\n",
    "cb.set_ticks([0, 0.04, 0.08])\n",
    "# cb.set_ticks([0, 0.04, 0.08, 0.12])\n",
    "# ax.text(0.1, 0.8, transform=ax.transAxes, fontsize=22)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = ...\n",
    "# np.mean(samples)\n",
    "# np.var(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0, 0])  # Mean vector (mu_x, mu_y)\n",
    "covariance = np.array([[1, 0.0],\n",
    "                       [0.0, 1]])\n",
    "\n",
    "# 2. Create a grid of points for the X and Y axes\n",
    "N = 1000 # Number of points in each dimension\n",
    "x = np.linspace(-3, 3, N)\n",
    "y = np.linspace(-3, 3, N)\n",
    "X, Y = np.meshgrid(x, y) # Create a 2D grid\n",
    "\n",
    "# 3. Combine X and Y into a single array of coordinates\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y\n",
    "\n",
    "# 4. Create a multivariate normal distribution object\n",
    "rv = multivariate_normal(mean, covariance)\n",
    "\n",
    "# 5. Calculate the PDF values for each point on the grid\n",
    "Z = rv.pdf(pos)\n",
    "\n",
    "# Plot contour of the 2D joint normal PDF\n",
    "fig = plt.figure(figsize=(7.5, 6), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "contour = ax.contourf(X, Y, Z, levels=20, cmap=\"Purples\", vmin=-0, vmax=.12, zorder=2, alpha=.9)\n",
    "ax.set_xlabel(\"$X_\\\\text{re}$\")\n",
    "ax.set_ylabel(\"$X_\\\\text{im}$\")\n",
    "ax.set_yticks([-2, 0, 2])\n",
    "ax.set_xticks([-2, 0, 2])\n",
    "for sp in ax.spines.values():\n",
    "    sp.set_visible(False)\n",
    "ax.grid(zorder=1)\n",
    "cb = plt.colorbar(contour, ax=ax, label=\"pdf\", shrink=0.6)\n",
    "# cb.set_ticks([0, 0.04, 0.08])\n",
    "cb.set_ticks([0, 0.04, 0.08, 0.12])\n",
    "# ax.text(0.1, 0.8, transform=ax.transAxes, fontsize=22)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot chi-squared distribution with 2, 4, and 6 degrees of freedom\n",
    "\n",
    "df_values = [2, 4, 6]  # Degrees of freedom\n",
    "x = np.linspace(0, 20, 1000)\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for df in df_values:\n",
    "    ax.plot(x, chi2.pdf(x, df), label=f\"{df}\", lw=3)\n",
    "# ax.set_title(\"Chi-Squared Distribution\")\n",
    "ax.set_xlabel(\"$y$\")\n",
    "ax.set_xticks([0, 5, 10, 15, 20])\n",
    "ax.set_yticks([0.1, 0.3, 0.5])\n",
    "ax.set_ylim(0, 0.55)\n",
    "ax.set_xlim(0, 20)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "# ax.set_ylabel(\"Probability Density Function (pdf)\")\n",
    "leg = ax.legend(fontsize=28)\n",
    "leg.set_title(\"DOF\", prop={\"size\": 22})\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot chi-squared with 2 DOF and non-central chi-squared\n",
    "\n",
    "df_list = [2, 4, 6]  # Degrees of freedom\n",
    "lambda_param = 5  # Non-centrality parameter\n",
    "x = np.linspace(0, 30, 1000)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "# ax.plot(x, chi2.pdf(x, df), label=f\"λ=0\", lw=3)\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "colors = cmap(np.linspace(0, 1, len(df_list)))\n",
    "for i, df in enumerate(df_list):\n",
    "    color = colors[i]\n",
    "    ax.plot(x, chi2.pdf(x, df), color=color, linestyle=\"--\", alpha=.5, lw=3)\n",
    "    ax.plot(x, ncx2.pdf(x, df, lambda_param), color=color, lw=3)\n",
    "ax.set_xlabel(\"$y$\")\n",
    "ax.set_xticks([0, 5, 10, 15, 20])\n",
    "ax.set_yticks([0.1, 0.3, 0.5])\n",
    "ax.set_ylim(0, 0.3)\n",
    "ax.set_xlim(0, 30)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "# ax.set_ylabel(\"Probability Density Function (pdf)\")\n",
    "handles = [plt.Line2D([0], [0], color=colors[i], lw=3) for i in range(len(df_list))]\n",
    "handles += [plt.Line2D([0], [0], color=\"black\", lw=3, linestyle=\"--\", alpha=.5)]\n",
    "labels = [f\"NCχ²({df}, 5)\" for df in df_list]\n",
    "labels += [\"χ²\"]\n",
    "leg = ax.legend(handles, labels, fontsize=22)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot chi-squared with 2 DOF and non-central chi-squared\n",
    "M = 4\n",
    "SNR_coh = 5  # Coherent SNR\n",
    "df = 2 * M  # Degrees of freedom\n",
    "lambda_param = M * SNR_coh  # Non-centrality parameter\n",
    "x = np.linspace(0, 50, 1000)\n",
    "\n",
    "noise_pdf = chi2.pdf(x, df)\n",
    "signal_plus_noise_pdf = ncx2.pdf(x, df, lambda_param)\n",
    "p_fd = .05\n",
    "threshold = chi2.ppf(1 - p_fd, df)\n",
    "print(f\"Threshold for Pfd={p_fd}: {threshold:.2f}\")\n",
    "p_d = 1 - ncx2.cdf(threshold, df, lambda_param)\n",
    "print(f\"Probability of Detection Pd={p_d:.3f}\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "colors = cmap([.2, .8])\n",
    "def lighten_color(color, amount=.5):\n",
    "    return np.array(color) + (1 - np.array(color)) * amount\n",
    "light_colors = [lighten_color(c) for c in colors]\n",
    "\n",
    "ax.fill_between(x, 0, signal_plus_noise_pdf, where=(x >= threshold), color=light_colors[1], alpha=1)\n",
    "ax.fill_between(x, 0, noise_pdf, where=(x >= threshold), color=light_colors[0], alpha=1)\n",
    "ax.plot(x, noise_pdf, label=f\"noise\", color=colors[0], lw=3)\n",
    "ax.plot(x, signal_plus_noise_pdf, label=f\"signal+noise\", color=colors[1], lw=3)\n",
    "ax.plot([threshold, threshold], [0, np.max(noise_pdf)], color=\"red\", linestyle=\"--\", lw=3, label=\"Threshold\")\n",
    "ax.text(.1, .8, f\"$P_{{fa}}={p_fd}$   $SNR_{{coh}}={SNR_coh}$ dB  M={M}\", transform=ax.transAxes, fontsize=22)\n",
    "ax.set_xlabel(\"$y$\")\n",
    "ax.set_xticks([0, 5, 10, 15, 20, 25, 30])\n",
    "ax.set_yticks([0.1, 0.3, 0.5])\n",
    "ax.set_ylim(0, 0.25)\n",
    "ax.set_xlim(0, 40)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "# ax.set_ylabel(\"Probability Density Function (pdf)\")\n",
    "leg = ax.legend(fontsize=22)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of detection vs coherent SNR for default M = 1, p_fd = 0.05\n",
    "\n",
    "SNR_coh_dB_arr = np.arange(-20, 50.2, 1.0)\n",
    "p_fa_arr = np.array([1e-6, 1e-5, 1e-4, 0.001, 0.01, 0.1])\n",
    "\n",
    "p_d_coh_arr = np.zeros((len(p_fa_arr), len(SNR_coh_dB_arr)))\n",
    "\n",
    "for i, p_fa in enumerate(p_fa_arr):\n",
    "    threshold = chi2.ppf(1 - p_fa, 2)  # for M = 1\n",
    "    print(f\"Threshold for Pfa={p_fa}: {threshold:.2f}\")\n",
    "    for j, SNR_coh_dB in enumerate(SNR_coh_dB_arr):\n",
    "        SNR_coh = 10 ** (SNR_coh_dB / 10)\n",
    "        lambda_param = 1 * SNR_coh  # M = 1\n",
    "        p_d_coh_arr[i, j] = 1 - ncx2.cdf(threshold, 2, lambda_param)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "cmap = plt.get_cmap(\"plasma\")\n",
    "colors = cmap(np.linspace(0, 1, len(p_fa_arr)))\n",
    "for i, p_fa in enumerate(p_fa_arr):\n",
    "    p_d = p_d_coh_arr[i, :]\n",
    "    ax.plot(SNR_coh_dB_arr, p_d, lw=3, color=colors[i], label=f\"$P_{{fa}}={p_fa}$\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Coherent SNR [dB]\")\n",
    "ax.set_ylabel(\"Probability of Detection $P_d$\")\n",
    "ax.set_xticks(np.arange(-5, 25, 5))\n",
    "ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(-5, 20)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SNR_coh = 25  # Coherent SNR\n",
    "SNR_coh_dB = 10 * np.log10(SNR_coh)\n",
    "\n",
    "M_arr = np.arange(1, 30)\n",
    "\n",
    "processing_gain_dB_arr = np.nan * np.zeros((len(p_fa_arr), len(M_arr)))\n",
    "\n",
    "for i, p_fa in enumerate(p_fa_arr):\n",
    "    for j, M in enumerate(M_arr):\n",
    "        df = 2 * M  # Degrees of freedom\n",
    "        threshold = chi2.ppf(1 - p_fa, df)\n",
    "        lambda_param = M * SNR_coh  # Non-centrality parameter\n",
    "        p_d = 1 - ncx2.cdf(threshold, df, lambda_param)\n",
    "        # figure out equiv_SNR that gives same p_d with M = 1\n",
    "        equiv_SNR_coh_dB = np.interp(p_d, p_d_coh_arr[i, :], SNR_coh_dB_arr)\n",
    "        if equiv_SNR_coh_dB > np.max(50):\n",
    "            continue\n",
    "        # print(p_d, equiv_SNR_coh_dB)\n",
    "        # equiv_SNR_coh = 10 ** (equiv_SNR_coh_dB / 10)\n",
    "        processing_gain_dB = equiv_SNR_coh_dB - SNR_coh_dB\n",
    "        processing_gain_dB_arr[i, j] = processing_gain_dB\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "cmap = plt.get_cmap(\"plasma\")\n",
    "colors = cmap(np.linspace(0, 1, len(p_fa_arr)))\n",
    "for i, p_fa in enumerate(p_fa_arr):\n",
    "    processing_gain_dB = processing_gain_dB_arr[i, :]\n",
    "    nan_mask = np.ones_like(processing_gain_dB)\n",
    "    nan_mask[processing_gain_dB > 35] = np.nan\n",
    "    ax.step(M_arr, processing_gain_dB * nan_mask, lw=3, color=colors[i], label=f\"$P_{{fa}}={p_fa}$\")\n",
    "\n",
    "noncoh_loss_func = lambda M, D_c: (1 + np.sqrt(1 + 9.2 * M / D_c)) / (1 + np.sqrt(1 + 9.2 / D_c))\n",
    "D_c_func = lambda p_fa, p_d: (special.erfcinv(2 * p_fa) + special.erfcinv(2 * (1 - p_d))) ** 2\n",
    "threshold = chi2.ppf(1 - p_fa, 2)\n",
    "p_d = 1 - ncx2.cdf(threshold, 2, SNR_coh)\n",
    "# D_c = D_c_func(p_fa=p_fa, p_d=p_d)\n",
    "D_c = 30\n",
    "print(f\"p_d = {p_d:.5f}  D_c = {D_c:.2f}\")\n",
    "# noncoh_gain_dB_arr = 10 * np.log10(M_arr / noncoh_loss_func(M_arr, D_c))\n",
    "# ax.step(M_arr, noncoh_gain_dB_arr, color=\"black\", lw=1, label=\"Non-coh. Gain Formula\")\n",
    "# noncoh_gain_dB_arr = 10 * np.log10(M_arr)\n",
    "# ax.step(M_arr, noncoh_gain_dB_arr, color=\"red\", lw=1, label=\"Non-coh. Gain Formula\")\n",
    "\n",
    "noncoh_gain_dB_arr = 6.79 * (1 + .253 * p_d) * (1 + np.log10(1 / p_fa) / 46.6) * np.log10(M_arr) * (1 - 0.14 * np.log10(M_arr) + 0.0183 * np.log10(M_arr)**2)\n",
    "ax.step(M_arr, noncoh_gain_dB_arr, color=\"black\", lw=1, label=\"Non-coh. Gain Formula\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"# Non-Coh. Integrations M\")\n",
    "ax.set_ylabel(\"Non-Coh. Processing Gain [dB]\")\n",
    "ax.set_xticks(np.arange(0, 55, 5))\n",
    "# ax.set_ylim(0, 35)\n",
    "ax.set_xlim(0, 20)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "\n",
    "p_fa_index = 4\n",
    "p_fa = p_fa_arr[p_fa_index]\n",
    "threshold = chi2.ppf(1 - p_fa, 2)\n",
    "\n",
    "# SNR_coh_dB_arr = np.arange(-20, 50.2, 0.1)\n",
    "M_arr = np.arange(1, 20)\n",
    "\n",
    "processing_gain_dB_arr = np.nan * np.zeros((len(SNR_coh_dB_arr), len(M_arr)))\n",
    "\n",
    "for i, SNR_coh_dB in enumerate(SNR_coh_dB_arr):\n",
    "    SNR_coh = 10 ** (SNR_coh_dB / 10)\n",
    "    for j, M in enumerate(M_arr):\n",
    "        df = 2 * M  # Degrees of freedom\n",
    "        lambda_param = M * SNR_coh  # Non-centrality parameter\n",
    "        p_d = 1 - ncx2.cdf(threshold, df, lambda_param)\n",
    "        # figure out equiv_SNR that gives same p_d with M = 1\n",
    "        equiv_SNR_coh_dB = np.interp(p_d, p_d_coh_arr[p_fa_index, :], SNR_coh_dB_arr)\n",
    "        if equiv_SNR_coh_dB > 50:\n",
    "            continue\n",
    "        # print(p_d, equiv_SNR_coh_dB)\n",
    "        # equiv_SNR_coh = 10 ** (equiv_SNR_coh_dB / 10)\n",
    "        processing_gain_dB = equiv_SNR_coh_dB - SNR_coh_dB\n",
    "        processing_gain_dB_arr[i, j] = processing_gain_dB\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "cmap = plt.get_cmap(\"plasma\")\n",
    "colors = cmap(np.linspace(0, 1, len(SNR_coh_dB_arr)))\n",
    "for i, SNR_coh_dB in enumerate(SNR_coh_dB_arr):\n",
    "    processing_gain_dB = processing_gain_dB_arr[i, :]\n",
    "    ax.step(M_arr, processing_gain_dB, lw=3, color=colors[i])\n",
    "\n",
    "noncoh_loss_func = lambda M, D_c: (1 + np.sqrt(1 + 9.2 * M / D_c)) / (1 + np.sqrt(1 + 9.2 / D_c))\n",
    "D_c_func = lambda p_fa, p_d: (special.erfcinv(2 * p_fa) + special.erfcinv(2 * (1 - p_d))) ** 2\n",
    "threshold = chi2.ppf(1 - p_fa, 2)\n",
    "p_d = 1 - ncx2.cdf(threshold, 2, SNR_coh)\n",
    "D_c = D_c_func(p_fa=0.01, p_d=p_d)\n",
    "print(f\"p_d = {p_d:.5f}  D_c = {D_c:.2f}\")\n",
    "noncoh_gain_dB_arr = 10 * np.log10(M_arr / noncoh_loss_func(M_arr, D_c))\n",
    "ax.step(M_arr, noncoh_gain_dB_arr, color=\"black\", lw=1, label=\"Non-coh. Gain\")\n",
    "\n",
    "# ax.legend()\n",
    "ax.set_xlabel(\"# Non-Coh. Integrations M\")\n",
    "ax.set_ylabel(\"Non-Coh. Processing Gain [dB]\")\n",
    "ax.set_xticks(np.arange(0, 55, 5))\n",
    "# ax.set_ylim(0, 35)\n",
    "ax.set_xlim(0, 20)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10 * np.log10(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnss_lectures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
